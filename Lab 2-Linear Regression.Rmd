---
title: "Lab 2---Linear Regression"
output:
  html_document:
    df_print: paged
---
Learning objectives.

- Split data into **training** and **test** data in ``R``
- Train/fit a linear regression model in ``R``
- Evaluate **prediction performance** of a linear regression model
- Perform small simulation study

### Analysis
You will recreate and extend the analysis of the brain weight data.

1. Read in (``red.table``) the Brain weight dataset. Examine (``head``) and summarize (``summary``) the data.
```{r}
brain<- read.table("brain.txt",header = T)
summary(brain)
```

2. Convert Sex and Age to factor variables so that ``lm`` can properly deal with them.

```{r}
library(tidyverse)
brain<-
  brain %>% 
  mutate(Sex = factor(Sex,levels=c("1","2"),labels = c("male","female")),
         Age = factor(Age,levels=c("1","2"),labels = c("20-46","46+")))
```

3. Split the data into training (70%) and test (30%) sets.

```{r}
set.seed(200)
n = nrow(brain)
train <- sample(1:237, floor(0.7*237))
trainset <- brain[train,]
testset<- brain[-train,]
```

```{r, plot brain weight and head size by sex category: male and female}
par(mar=c(5,5,1,1))
plot(trainset$Brain.weight,trainset$Head.size, col=trainset$Sex)
#points(pch=16,col='red4',cex=1)
#points(pch=16,col='steelblue',cex=1)
```

```{r}
library(ggplot2)
trainset %>% 
  ggplot(mapping=aes(x=Brain.weight,y=Head.size, col= Sex))+
  geom_point()+
  labs(title = "Brain weight and head size by sex", x = "Head Size",y = "Brain Weight")
```

4. Fit a linear regression model with brain weight as the outcome and head Size, Sex, and Age as predictors. What is the interpretation of the coefficients for Sex and Age? Compute the training and test RMSE and $R^2$. Does adding Age improves *prediction performance* over the model with Sex and Head size alone?

```{r}
# a linear model between brain weight to head size, Sex and Age
model2<-lm(Brain.weight~Head.size+Sex+Age, trainset)  
model2

#linear relationship between brain weight to head size ,Sex
model1<-lm(Brain.weight~Head.size+Sex, trainset) 
model1


# Compute the training set RMSE and R^2 of the model with Age
RMSE_train_age<- sqrt(sum(residuals(model2))^2/(nrow(trainset)-2))
RMSE_train_age

RSS<- sum((residuals(model2))^2)
TSS <- sum((trainset$Brain.weight-mean(trainset$Brain.weight))^2)
R2_train_age<- 1-RSS/TSS
R2_train_age

# Compute the training set RMSE and R^2 of the model without Age
RMSE_train<- sqrt(sum(residuals(model1))^2/(nrow(trainset)-2))
RMSE_train

RSS<- sum((residuals(model1))^2)
TSS <- sum((trainset$Brain.weight-mean(trainset$Brain.weight))^2)
R2_train<- 1-RSS/TSS
R2_train

## Compute the testing set RMSE and R^2 of the model with Age
predi<- predict(model2,newdata=testset)
RMSE_test_age <- sqrt(sum(testset$Brain.weight-predi)^2)/(nrow(testset))
RMSE_test_age

RSS<- sum(testset$Brain.weight-predi)^2
TSS <- sum((testset$Brain.weight-mean(testset$Brain.weight))^2)
R2_test_age<- 1-RSS/TSS
R2_test_age


## Compute the testing set RMSE and R^2 of the model without Age
predi_2<- predict(model1,newdata=testset)
RMSE_test <- sqrt(sum(testset$Brain.weight-predi_2)^2)/(nrow(testset))
RMSE_test

RSS<- sum(testset$Brain.weight-predi_2)^2
TSS <- sum((testset$Brain.weight-mean(testset$Brain.weight))^2)
R2_test<- 1-RSS/TSS
R2_test
```
__Age is significantly associated with brain weight(P<0.005), while sex is not(P=0.2228). When holding other parameter constant,people who age between 20 to 46 years old, the mean of brain weight is 440g, and the mean of brain weight is 24.9g lower when people age over 46 years. The mean of brain weight in female is 16.9 lighter than male mean brain weight, when holding other parameter constant.
__With covariate age model,the RMSE value of training set and test set are 7.130669e-15, 5.401917e-14 respectively. The $R2$ value are 0.6228036, 0.61227 respectively. The RMSE value of model without age in training and test are 11.54393,14.53929 respectively. The $R^2$ value are 0.3876744 and 0.02868211.
In test set, the RMSE value of model with age is smaller than the value of model without age. Adding age improves the prediction performance over the model with sex and head size only.


5. Explore whether a linear regression model with separate intercepts and separate slopes for $20 \le$ Age $<$ 46 and Age $\ge$ 46 improves prediction performance (hint: you can, for example, specify an interaction between Age and Head size including `` Head.Size:Age`` in the model formula.

```{r}
model3<-lm(Brain.weight~Head.size*Age+Sex, trainset) 
summary(model3)
#compute a model with interaction between Age and head size
predi_3<- predict(model3,newdata=testset)
RMSE_test3 <- sqrt(sum(testset$Brain.weight-predi_3)^2)/(nrow(testset))
RMSE_test3

RSS<- sum(testset$Brain.weight-predi_3)^2
TSS <- sum((testset$Brain.weight-mean(testset$Brain.weight))^2)
R2_test3<- 1-RSS/TSS
R2_test3
```

__There is no significant interaction between head size and age (p=0.253). However, with two different categories of age in the model improves a predictive performance. The RMSE decrease from 14.5 to 11.9 after adding an interaction between head size and age.


### Simulation
You will perform a small simulation study to investigate the degree to which assessing prediction performance in *the same data* used to train/fit a model -- rather than using a separate test data set -- leads to an overly optimistic assessment of prediction performance. Of particular interest is to investigate how the degree of overoptimistic assessment is affected by i) the size of the training data and ii) the level of noise in the data. The simulation will loosely mimic the brain weight data.

1. Set the training sample size to ``n_train=100``, the test sample size to ``n_test=50``, and the total sample size to ``n = n_train + n_test = 150`` (the train/test split is 2/3 train to 1/3 test rather than the more usual 0.8 to 0.2 to prevent the test set from being too small).

```{r, set training and test sets}
set.seed(100)
n <- 1:150
n_train <- sample(n,100)
n_test <- sample(n,50)
```

2. Generate a variable/vector ``Head.size`` of size ``n`` drawn from a normal distribution with population mean and population standard deviations equal to the sample mean and sample standard deviation, respectively, of the Head.Size variable in the real brain weight data.

```{r generate 'Head.size'variable}
size<- rnorm(150,mean = mean(brain$Head.size), sd= sd(brain$Head.size))
```

3. Generate a binary variable/vector ``Sex``= Female/Male of size ``n`` with a population frequency of Sex==Female/Male matching the observed frequencies of the variable Sex in the real brain weight data (hint: use ``rbinom`` to generate samples form a binomial distribution: ``rbinom(n, size=1, prob=Malefreq)``, where ``Malefreq`` was previously computed).

```{r}
table(brain$Sex)
Malefreq <- 134/(237)
sex<-rbinom(150, size=1, prob=Malefreq)
```

4. Similarly, generate a binary variable/vector ``Age``= <= 46/ > 46 with population frequencies for <= 46 and > 46 matching the observed frequencies of the variable Age in the the real brain weight data.
```{r}
table(brain$Age)
Age_46<-127/(237) 
age<-rbinom(150, size=1, prob=Age_46)
```

5. Generate a variable/vector ``Brain.weight`` of size ``n`` according to the linear model ``Brain.weight = b0 + ba * Age + bs * Sex + bh * Head.size``. Use the coefficients $\widehat{\beta_0}, \widehat{\beta_{A}},  \widehat{\beta_{S}}$, and $\widehat{\beta_{H}}$ obtained from fitting the corresponding linear regression model to the full real brain weight data set. 

```{r}
weight<- 398.4976+0.2481*size-16.8649*sex-24.9261*age
```

6. Generate a noise/error vector ``noise`` of size ``n`` drawn from a normal distribution with mean 0 and variance equal to that of the residual variance in the linear regression model fitted above on the full real brain weight data set. Add the noise to Brain.weight: ``Brain.weight = Brain.weight + noise``.

```{r}
noise<- rnorm(150, mean = 0, sd=sd(model2$residuals))
brain_weight<- weight + noise  
```

7. Construct a data frame containing the generated variables ``Sex``, ``Age``, ``Brain.weight``, and ``Head.size`` 
```{r, construct a simulation data frame}
simdata <- data.frame(sex,age,brain_weight,size)
```

8. Split the data into training (``size n_train``) and test (``size n_test``) sets
```{r,split into training and test sets}
simtrain<- sample(1:150, floor((2/3)*150))
simdata_train<- simdata[simtrain,] 
simdata_test<- simdata[-simtrain,]
```

9. Fit the model ``Brain.weight ~ b0 + ba * Age + bs * Sex + bh * Head.size`` to the training data.
```{r, fit a linear model to simulation training set}
model4 <-lm(brain_weight~size+age+sex,simdata_train)
model4
```

10. Compute the training and test RMSE and $R^2$.
```{r, compute the RMSE and $R^2$}
# Compute the training RMSE and R^2 of the model 
RMSE_simtrain<- sqrt(sum(residuals(model4))^2/(nrow(simdata_train)-2))
RMSE_simtrain

RSS<- sum((residuals(model4))^2)
TSS <- sum((simdata_train$brain_weight-mean(simdata_train$brain_weight))^2)
R2_simtrain<- 1-RSS/TSS
R2_simtrain

## Compute the testing set RMSE and R^2 of the model 
predi_4<- predict(model4,newdata=simdata_test)
RMSE_simtest <- sqrt(sum(simdata_test$brain_weight-predi_4)^2)/(nrow(simdata_test))
RMSE_simtest

RSS<- sum(simdata_test$brain_weight-predi_4)^2
TSS <- sum((simdata_test$brain_weight-mean(simdata_test$brain_weight))^2)
R2_simtest<- 1-RSS/TSS
R2_simtest
```
__The RMSE and $R^2$in training set are 4.665418e-15, 0.5107051 respectively.
__The RMSE and $R^2$in test set are 1.97945, 0.9802943respectively.

11. Repeat steps 2 to  100 times (save the RMSE's and $R^2$'s from each simulation replicate).
```{r, repeat steps to 100 times}
RMSE_train <- numeric(100)
RMSE_test <- numeric(100)
R2_train <- numeric(100)
R2_test <- numeric(100)
nreps<-100
for (i in 1:nreps){
  # simulate nreps training and test data sets
  simtrain_rep<- sample(1:150, floor((2/3)*150))
  simdata_train_rep<- simdata[simtrain_rep,] 
  simdata_test_rep<- simdata[-simtrain_rep,]
  
  model_sim <-lm(brain_weight~size+age+sex,simdata_train_rep) 
  simpredi<- predict(model_sim,newdata=simdata_test_rep)
  
  RMSE_train[i]= sqrt(sum(residuals(model_sim))^2/(nrow(simdata_train_rep)))
  RMSE_test[i]= sqrt((sum(simdata_test_rep$brain_weight-simpredi)^2))/(nrow(simdata_test_rep))
  
  R2_train[i] = 1-sum((residuals(model_sim))^2)/sum((simdata_train_rep$brain_weight-mean(simdata_train_rep$brain_weight))^2)
  R2_test[i] = 1-sum((simdata_test_rep$brain_weight-simpredi)^2)/sum((simdata_test_rep$brain_weight-mean(simdata_test_rep$brain_weight))^2)
}
  
```

12. Compute the average training and test RMSE ($R^2$) across the 100 simulation replicates. 

```{r}
R2_train_ave<- mean(R2_train);R2_test_ave<- mean(R2_test);
RMSE_train_ave <- mean(RMSE_train);RMSE_test_ave <- mean(RMSE_test);
round(c(Ave_R2_train=R2_train_ave,Ave_R2_test=R2_test_ave,Ave_RMSE_train=RMSE_train_ave,Ave_RMSE_test=RMSE_test_ave),3)
```

13. Visually (e.g. scatter plot, boxplot) evaluate the degree of optimistic assessment when training and testing on the same data.
```{r}
# scatter plot
par(mar=c(5,5,1,1))
plot(R2_test,pch=16,col='red4',cex=1,cex.lab=2, ylab = expression('R'^2))
points(R2_train,pch=16,col='steelblue',cex=1)
abline(h=R2_train_ave, col='steelblue',lwd=3)
abline(h=R2_test_ave, col='red4',lwd=3)

#boxplot
par(mar=c(5,5,1,1))
boxplot(c(R2_test,R2_train) ~ rep(c('Test R^2', 'Train R^2'), each=nreps), pch=16,col='steelblue',cex=2,cex.axis=2, xlab='',ylab='',names=c('Test','Train'))

```

14. Comment on the results of the simulation. 



15. Investigate how the results change as: 
    i. ``n_train`` gets larger (say ``n_train=300`` and ``n_train=1000``) and
    ii. the standard deviation of the noise variable ``noise`` gets larger (say 1.5- and 2-fold lager than in the baseline simulation). Summarize and comment on your results.
 




